{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fdc6cf-7383-4231-8886-746735f080ea",
   "metadata": {},
   "source": [
    "<center><h1> Body Tracking Using MediaPipe  </h1>\n",
    "\n",
    "\n",
    "<h3> \n",
    "    Wim Pouw ( wim.pouw@donders.ru.nl )<br>James Trujillo ( james.trujillo@donders.ru.nl )<br>\n",
    "    18-11-2021 </h3>\n",
    "    \n",
    "<img src=\"./images/BOOTCAMP.png\"> </center>\n",
    "\n",
    "<h3> Info documents </h3>\n",
    "This module provides a simple demonstration of how to use MediaPipe for motion tracking of a single person. The approach provides a lightweight motion tracking solution, and several distinct advantages in the type of output that we get\n",
    "<br><br>\n",
    "\n",
    "* location code: \n",
    "https://github.com/WimPouw/EnvisionBootcamp2021/tree/main/Python/MediaBodyTracking\n",
    "\n",
    "* citation: \n",
    "Pouw, W.T.J.L  &  Trujillo, J.P.(2021-11-18). <i> Body Tracking Using MediaPipe </i> \\[day you visited the site]. Retrieved from: https://github.com/WimPouw/EnvisionBootcamp2021/tree/main/Python/MediaBodyTracking \n",
    "\n",
    "<h4>resources</h4>\n",
    "* https://github.com/google/mediapipe\n",
    "<br><br>\n",
    "* Lugaresi, C., Tang, J., Nash, H., McClanahan, C., Uboweja, E., Hays, M., ... & Grundmann, M. (2019). Mediapipe: A framework for building perception pipelines. arXiv preprint arXiv:1906.08172.\n",
    "<br>\n",
    "<h4>Required</h4>\n",
    "Before you start, make sure the following python packages are installed:\n",
    "\n",
    "* opencv-python\n",
    "* mediapipe\n",
    "* numpy\n",
    "* pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed288448",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import cv2\n",
    "import mediapipe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    " \n",
    "drawingModule = mediapipe.solutions.drawing_utils\n",
    "poseModule = mediapipe.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9fd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all videos in mediafolder\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"./MediaToAnalyze/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "#time series output folder\n",
    "foldtime = \"./Timeseries_Output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6bdc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some preperatory functions and lists for saving the data\n",
    "\n",
    "\n",
    "#take some google classification object and convert it into a string\n",
    "def makegoginto_str(gogobj):\n",
    "    gogobj = str(gogobj).strip(\"[]\")\n",
    "    gogobj = gogobj.split(\"\\n\")\n",
    "    return(gogobj[:-1]) #ignore last element as this has nothing\n",
    "\n",
    "#landmarks 33x\n",
    "markers = ['NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_OUTER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER',\n",
    "          'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW', \n",
    "          'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX',\n",
    "          'LEFT_THUMB', 'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE',\n",
    "          'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX']\n",
    "\n",
    "#check if there are numbers in a string\n",
    "def num_there(s):\n",
    "    return any(i.isdigit() for i in s)\n",
    "\n",
    "#make the stringifyd position traces into clean values\n",
    "def listpostions(newsamplemarks):\n",
    "    tracking_p = []\n",
    "    for value in newsamplelmarks:\n",
    "        if num_there(value):\n",
    "            stripped = value.split(':', 1)[1]\n",
    "            stripped = stripped.strip() #remove spaces in the string if present\n",
    "            tracking_p.append(stripped) #add to this list  \n",
    "    return(tracking_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36094bc2-0917-4c47-970b-7af51ede90cc",
   "metadata": {},
   "source": [
    "Once we have our preparatory functions set and packages loaded. We can get to tracking. In the code block below, we will do 3 things. The code will perform the actual tracking using MediaPipe (functions such as <i> pose, posemodule</i>), draw the tracked points back onto each frame of the video (using <i>cv2</i>), and save the coordinates of the tracked points into a dataframe (using <i>pandas</i>) for analysis or further processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9b06b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544.0 362.0 30.013573403038997\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ff in onlyfiles:\n",
    "    capture = cv2.VideoCapture(mypath+ff)\n",
    "    frameWidth = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    frameHeight = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "    print(frameWidth, frameHeight, fps )\n",
    "    #pose tracking with keypoints save!\n",
    "    #make an 'empty' video file where we can store the visualized tracking\n",
    "    samplerate = fps #make the same as current video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID') #(*'XVID')\n",
    "    out = cv2.VideoWriter('Videotracking_output/'+ff[:-4]+'.avi', fourcc, fps= samplerate, frameSize = (1280, 720))\n",
    "\n",
    "\n",
    "    #make a variable list with x, y, z, info where data is appended to\n",
    "    markerxyz = []\n",
    "    for mark in markers:\n",
    "        for pos in ['X', 'Y', 'Z', 'visibility']:\n",
    "            nm = pos + \"_\" + mark\n",
    "            markerxyz.append(nm)\n",
    "    addvariable = ['time']\n",
    "    addvariable.extend(markerxyz)\n",
    "\n",
    "    time = 0\n",
    "    timeseries = [addvariable]\n",
    "    #MAIN ROUTINE\n",
    "    with poseModule.Pose(min_detection_confidence=0.5, model_complexity = 2, min_tracking_confidence=0.75, smooth_landmarks = True) as pose:\n",
    "         while (True):\n",
    "            ret, frame = capture.read()\n",
    "            if ret == True:\n",
    "                results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                if results.pose_landmarks != None:\n",
    "                    newsamplelmarks = makegoginto_str(results.pose_world_landmarks)\n",
    "                    newsamplelmarks = listpostions(newsamplelmarks)\n",
    "                    fuldataslice = [str(time)]\n",
    "                    fuldataslice.extend(newsamplelmarks) #add positions\n",
    "                    timeseries.append(fuldataslice) #append to the timeries data\n",
    "                        #get information about hand index [0], hand confidence [1], handedness [2]              \n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                    drawingModule.draw_landmarks(frame, results.pose_landmarks, poseModule.POSE_CONNECTIONS)\n",
    "                    #for point in handsModule.HandLandmark:\n",
    "                        #normalizedLandmark = results.pose_landmarks.landmark[point]\n",
    "                        #pixelCoordinatesLandmark = drawingModule._normalized_to_pixel_coordinates(normalizedLandmark.x, normalizedLandmark.y, frameWidth, frameHeight)\n",
    "                        #cv2.circle(frame, pixelCoordinatesLandmark, 5, (0, 255, 0), -1)\n",
    "                cv2.imshow('MediaPipe Pose', frame)\n",
    "                out.write(frame)  ################################################comment this if you dont want to make a video\n",
    "                time = round(time+1000/samplerate)\n",
    "                if cv2.waitKey(1) == 27:\n",
    "                    break\n",
    "            if ret == False:\n",
    "                break\n",
    "    out.release()\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    ####################################################### data to be written row-wise in csv fil\n",
    "    data = timeseries\n",
    "\n",
    "    # opening the csv file in 'w+' mode\n",
    "    file = open(foldtime + ff[:-4]+'.csv', 'w+', newline ='')\n",
    "    #write it\n",
    "    with file:    \n",
    "        write = csv.writer(file)\n",
    "        write.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6906da-f698-4e07-a64b-d906e1e0904a",
   "metadata": {},
   "source": [
    "Here's a sample frame from the output video: <br>\n",
    "<img src=\"./images/mediapipe_body.png\"> </center> <br>\n",
    "As well as a sample of the data that we produced:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "782c089b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>X_NOSE</th>\n",
       "      <th>Y_NOSE</th>\n",
       "      <th>Z_NOSE</th>\n",
       "      <th>visibility_NOSE</th>\n",
       "      <th>X_LEFT_EYE_INNER</th>\n",
       "      <th>Y_LEFT_EYE_INNER</th>\n",
       "      <th>Z_LEFT_EYE_INNER</th>\n",
       "      <th>visibility_LEFT_EYE_INNER</th>\n",
       "      <th>X_LEFT_EYE</th>\n",
       "      <th>...</th>\n",
       "      <th>Z_RIGHT_HEEL</th>\n",
       "      <th>visibility_RIGHT_HEEL</th>\n",
       "      <th>X_LEFT_FOOT_INDEX</th>\n",
       "      <th>Y_LEFT_FOOT_INDEX</th>\n",
       "      <th>Z_LEFT_FOOT_INDEX</th>\n",
       "      <th>visibility_LEFT_FOOT_INDEX</th>\n",
       "      <th>X_RIGHT_FOOT_INDEX</th>\n",
       "      <th>Y_RIGHT_FOOT_INDEX</th>\n",
       "      <th>Z_RIGHT_FOOT_INDEX</th>\n",
       "      <th>visibility_RIGHT_FOOT_INDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>396</td>\n",
       "      <td>0.538114</td>\n",
       "      <td>-0.060236</td>\n",
       "      <td>-0.050362</td>\n",
       "      <td>0.999510</td>\n",
       "      <td>0.555659</td>\n",
       "      <td>-0.049128</td>\n",
       "      <td>-0.045910</td>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055976</td>\n",
       "      <td>0.933046</td>\n",
       "      <td>-0.283941</td>\n",
       "      <td>0.462588</td>\n",
       "      <td>-0.274494</td>\n",
       "      <td>0.989258</td>\n",
       "      <td>-0.450967</td>\n",
       "      <td>-0.337301</td>\n",
       "      <td>-0.104251</td>\n",
       "      <td>0.955913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429</td>\n",
       "      <td>0.443146</td>\n",
       "      <td>-0.034791</td>\n",
       "      <td>0.088246</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.458518</td>\n",
       "      <td>-0.032522</td>\n",
       "      <td>0.108830</td>\n",
       "      <td>0.998529</td>\n",
       "      <td>0.460630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109341</td>\n",
       "      <td>0.936138</td>\n",
       "      <td>-0.410189</td>\n",
       "      <td>0.583331</td>\n",
       "      <td>-0.182948</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>-0.638469</td>\n",
       "      <td>-0.215301</td>\n",
       "      <td>-0.182827</td>\n",
       "      <td>0.958650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462</td>\n",
       "      <td>0.440275</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>0.067064</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.084740</td>\n",
       "      <td>0.994618</td>\n",
       "      <td>0.455070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109471</td>\n",
       "      <td>0.928449</td>\n",
       "      <td>-0.477191</td>\n",
       "      <td>0.576702</td>\n",
       "      <td>-0.025761</td>\n",
       "      <td>0.980243</td>\n",
       "      <td>-0.694765</td>\n",
       "      <td>-0.208185</td>\n",
       "      <td>-0.178391</td>\n",
       "      <td>0.954599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>627</td>\n",
       "      <td>0.129521</td>\n",
       "      <td>0.136490</td>\n",
       "      <td>0.031299</td>\n",
       "      <td>0.996851</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>0.130574</td>\n",
       "      <td>-0.018655</td>\n",
       "      <td>0.995154</td>\n",
       "      <td>0.115800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424263</td>\n",
       "      <td>0.929862</td>\n",
       "      <td>-0.453918</td>\n",
       "      <td>0.379679</td>\n",
       "      <td>-0.243619</td>\n",
       "      <td>0.975504</td>\n",
       "      <td>0.408910</td>\n",
       "      <td>0.111685</td>\n",
       "      <td>-0.371516</td>\n",
       "      <td>0.949324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>660</td>\n",
       "      <td>0.139343</td>\n",
       "      <td>0.048282</td>\n",
       "      <td>0.262759</td>\n",
       "      <td>0.997156</td>\n",
       "      <td>0.129757</td>\n",
       "      <td>0.025985</td>\n",
       "      <td>0.275302</td>\n",
       "      <td>0.995634</td>\n",
       "      <td>0.127441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.327688</td>\n",
       "      <td>0.929971</td>\n",
       "      <td>-0.452408</td>\n",
       "      <td>0.286135</td>\n",
       "      <td>-0.220267</td>\n",
       "      <td>0.951644</td>\n",
       "      <td>0.571573</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>-0.259778</td>\n",
       "      <td>0.913952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time    X_NOSE    Y_NOSE    Z_NOSE  visibility_NOSE  X_LEFT_EYE_INNER  \\\n",
       "0   396  0.538114 -0.060236 -0.050362         0.999510          0.555659   \n",
       "1   429  0.443146 -0.034791  0.088246         0.999035          0.458518   \n",
       "2   462  0.440275  0.011850  0.067064         0.996508          0.453032   \n",
       "3   627  0.129521  0.136490  0.031299         0.996851          0.119219   \n",
       "4   660  0.139343  0.048282  0.262759         0.997156          0.129757   \n",
       "\n",
       "   Y_LEFT_EYE_INNER  Z_LEFT_EYE_INNER  visibility_LEFT_EYE_INNER  X_LEFT_EYE  \\\n",
       "0         -0.049128         -0.045910                   0.999261    0.557287   \n",
       "1         -0.032522          0.108830                   0.998529    0.460630   \n",
       "2          0.007117          0.084740                   0.994618    0.455070   \n",
       "3          0.130574         -0.018655                   0.995154    0.115800   \n",
       "4          0.025985          0.275302                   0.995634    0.127441   \n",
       "\n",
       "   ...  Z_RIGHT_HEEL  visibility_RIGHT_HEEL  X_LEFT_FOOT_INDEX  \\\n",
       "0  ...     -0.055976               0.933046          -0.283941   \n",
       "1  ...     -0.109341               0.936138          -0.410189   \n",
       "2  ...     -0.109471               0.928449          -0.477191   \n",
       "3  ...     -0.424263               0.929862          -0.453918   \n",
       "4  ...     -0.327688               0.929971          -0.452408   \n",
       "\n",
       "   Y_LEFT_FOOT_INDEX  Z_LEFT_FOOT_INDEX  visibility_LEFT_FOOT_INDEX  \\\n",
       "0           0.462588          -0.274494                    0.989258   \n",
       "1           0.583331          -0.182948                    0.989362   \n",
       "2           0.576702          -0.025761                    0.980243   \n",
       "3           0.379679          -0.243619                    0.975504   \n",
       "4           0.286135          -0.220267                    0.951644   \n",
       "\n",
       "   X_RIGHT_FOOT_INDEX  Y_RIGHT_FOOT_INDEX  Z_RIGHT_FOOT_INDEX  \\\n",
       "0           -0.450967           -0.337301           -0.104251   \n",
       "1           -0.638469           -0.215301           -0.182827   \n",
       "2           -0.694765           -0.208185           -0.178391   \n",
       "3            0.408910            0.111685           -0.371516   \n",
       "4            0.571573            0.054125           -0.259778   \n",
       "\n",
       "   visibility_RIGHT_FOOT_INDEX  \n",
       "0                     0.955913  \n",
       "1                     0.958650  \n",
       "2                     0.954599  \n",
       "3                     0.949324  \n",
       "4                     0.913952  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_body = pd.read_csv(foldtime + ff[:-4]+'.csv')\n",
    "df_body.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ac384-cf80-4720-b90f-94decf96cc00",
   "metadata": {},
   "source": [
    "One advantage of the output that we get here is that even though we used a 2D video, we get 3D tracking coordinates. This is possible because the MediaPipe detector was trained on hand coordinates for which the depth was known. As the authors state: <i>\"Synthetic dataset: To even better cover the possible hand poses and provide additional supervision for depth, we render a high-quality synthetic hand model over various backgrounds and map it to the corresponding 3D coordinates. We use a commercial 3D hand model that is rigged with 24 bones and includes 36 blendshapes, which control fingers and palm thickness. The model also provides 5 textures with different skin tones. We created video sequences of transformation between hand poses and sampled 100K images from the videos.\" Zhang et al., 2020 </i><br><br>\n",
    "Additionally, the coordinates provided here are given in meters, with the absolute origin (0,0,0) being the center between the hips. This is advantageous because it reduces variability between videos when the distance to camera also varies. <br><br>\n",
    "The major disadvantage to this method is that it is only capable of tracking a single individual at a time. For videos of one speaker/actor, this isn't an issue of course. But if we're interested in multi-party interactions and cannot (or do not wish to) split the video into different individuals (e.g., because of overlapping space between them), we need to use a different solution. We discuss a couple of such options in the modules covering hand tracking with MediaPipe, tracking using DeepLabCut, and tracking using OpenPose."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
